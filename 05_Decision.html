<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>STA 5320 Predictive Analytics - 5&nbsp; Decision Trees</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./06_Ensemble.html" rel="next">
<link href="./04_SVM.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="webex.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./05_Decision.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Decision Trees</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"></a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Tidymodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Tidymodels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Decision.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Decision Trees</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_Ensemble.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Ensemble Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_Dimension.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Dimensionality Reduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_Clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">5.1</span> Introduction</a></li>
  <li><a href="#structure-of-decision-trees" id="toc-structure-of-decision-trees" class="nav-link" data-scroll-target="#structure-of-decision-trees"><span class="header-section-number">5.2</span> Structure of Decision Trees</a></li>
  <li><a href="#example-using-tidymodels" id="toc-example-using-tidymodels" class="nav-link" data-scroll-target="#example-using-tidymodels"><span class="header-section-number">5.3</span> Example Using <code>tidymodels</code></a></li>
  <li><a href="#decision-trees-for-regression" id="toc-decision-trees-for-regression" class="nav-link" data-scroll-target="#decision-trees-for-regression"><span class="header-section-number">5.4</span> 4. Decision Trees for Regression</a></li>
  <li><a href="#advantages-and-disadvantages" id="toc-advantages-and-disadvantages" class="nav-link" data-scroll-target="#advantages-and-disadvantages"><span class="header-section-number">5.5</span> Advantages and Disadvantages</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Decision Trees</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><section id="introduction" class="level2" data-number="5.1"><h2 data-number="5.1" class="anchored" data-anchor-id="introduction">
<span class="header-section-number">5.1</span> Introduction</h2>
<p>Decision trees are a fundamental machine learning technique used for both classification and regression tasks. At their core, decision trees model decisions and their possible consequences, including chance event outcomes, resource costs, and utility. They are a non-parametric supervised learning method used for classifying data points (in classification trees) and predicting continuous values (in regression trees).</p>
<p><strong>Historical Context and Evolution</strong>: Decision trees have been a part of the computational and statistical landscape since the 1960s, evolving from their initial use in decision analysis and research into an indispensable tool in the machine learning toolkit. The development of algorithms such as ID3 by Ross Quinlan in the 1980s and its successors, C4.5 and CART (Classification and Regression Trees), marked significant milestones in making decision trees more efficient, accurate, and applicable to a broader range of data types and machine learning problems.</p>
<p><strong>Intuition Behind Decision Trees</strong>: At the heart of decision trees is a simple yet powerful idea—mimicking human decision-making processes through a structured, hierarchical approach. By breaking down complex decisions into a series of simpler choices, each based on specific attributes or features of the data, decision trees can navigate the intricacies of real-world data and arrive at predictions or classifications. This intuitive approach to problem-solving, mirroring the “if-then-else” decision-making logic, makes decision trees both accessible and powerful for addressing diverse analytical challenges.</p>
<p><strong>Significance in Machine Learning and Artificial Intelligence</strong>: Decision trees serve as foundational building blocks for more complex models, such as random forests and gradient boosting machines, highlighting their importance not only as standalone models but also as components in ensemble methods. Their ability to handle both numerical and categorical data, accommodate non-linear relationships without assuming data distribution, and provide interpretable models that can be easily visualized and understood, underscores their versatility and broad applicability. Furthermore, the role of decision trees in feature importance analysis, where they help in identifying the most significant predictors in a dataset, showcases their utility in exploratory data analysis and model refinement processes.</p>
</section><section id="structure-of-decision-trees" class="level2" data-number="5.2"><h2 data-number="5.2" class="anchored" data-anchor-id="structure-of-decision-trees">
<span class="header-section-number">5.2</span> Structure of Decision Trees</h2>
<p>Decision trees are graphical representations of decision-making processes. They consist of nodes and branches, where each node represents a decision point or an outcome, and branches represent the choices leading to those decisions or outcomes. The structure can be divided into three main components:</p>
<section id="root-node" class="level4"><h4 class="anchored" data-anchor-id="root-node">1. <strong>Root Node</strong>:</h4>
<p>This is the starting point of the tree, where the entire dataset is considered before any splits are made. The root node identifies the feature that provides the most significant information gain or the best split based on a specific criterion, like Gini impurity or entropy for classification trees, and variance reduction for regression trees.</p>
<p><strong>Gini Impurity</strong></p>
<p>Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. The Gini impurity of a dataset is minimal (zero) when all the elements belong to a single class, indicating perfect homogeneity.</p>
<p>The Gini impurity of a node can be calculated using the formula:</p>
<p><span class="math display">\[
Gini(t) = 1 - \sum_{i=1}^{J} p_i^2
\]</span></p>
<p>where <span class="math inline">\(p_i\)</span> is the proportion of the samples that belong to class <span class="math inline">\(i\)</span> at a given node <span class="math inline">\(t\)</span>, and <span class="math inline">\(J\)</span> is the number of classes. The goal in splitting a node is to achieve the lowest possible Gini impurity in the resulting child nodes.</p>
<p><strong>Example: Iris dataset</strong></p>
<p>The Iris dataset consists of 150 observations of iris flowers, each with 4 features (sepal length, sepal width, petal length, and petal width) and classified into one of three species (setosa, versicolor, virginica).</p>
<p>Imagine we have a subset of the Iris dataset with 10 observations:</p>
<ul>
<li>6 of Iris setosa</li>
<li>3 of Iris versicolor</li>
<li>1 of Iris virginica</li>
</ul>
<p>For our subset:</p>
<ul>
<li>The proportion of Iris setosa (<span class="math inline">\(p_{setosa}\)</span>) = 6/10 = 0.6</li>
<li>The proportion of Iris versicolor (<span class="math inline">\(p_{versicolor}\)</span>) = 3/10 = 0.3</li>
<li>The proportion of Iris virginica (<span class="math inline">\(p_{virginica}\)</span>) = 1/10 = 0.1</li>
</ul>
<p>Plugging these into the formula gives us:</p>
<p><span class="math display">\[
Gini(t) = 1 - (0.6^2 + 0.3^2 + 0.1^2) = 1 - (0.36 + 0.09 + 0.01) = 1 - 0.46 = 0.54
\]</span></p>
<p><strong>Interpretation</strong></p>
<p>The Gini impurity of 0.54 indicates a moderate level of impurity or mixture of classes within this subset of the Iris dataset. A Gini impurity of 0 would mean the subset is perfectly homogeneous (all observations belong to a single class), while a Gini impurity of 0.5 (for a binary classification) or higher in multi-class scenarios like ours suggests a higher level of mixture among classes.</p>
<p>In the context of building a decision tree, the goal would be to find the feature and split point that decrease the Gini impurity the most for the resulting subsets. For example, if splitting by petal length at a certain threshold results in two groups—one with mainly Iris setosa and another with a mixture of Iris versicolor and Iris virginica—but both with lower Gini impurity scores than 0.54, that split improves the homogeneity of our subsets with respect to the target variable (species).</p>
<p><strong>Entropy</strong></p>
<p>Entropy, a concept borrowed from information theory, measures the level of uncertainty or disorder within a dataset. In the context of decision trees, entropy can be used to quantify the impurity or randomness in the dataset’s class distribution at a node. A dataset with elements from only one class has zero entropy (no disorder), while a dataset evenly split between two or more classes has higher entropy.</p>
<p>The entropy of a node is given by the formula:</p>
<p><span class="math display">\[
Entropy(t) = -\sum_{i=1}^{J} p_i \log_2(p_i)
\]</span></p>
<p>Here, <span class="math inline">\(p_i\)</span> represents the proportion of the samples belonging to class <span class="math inline">\(i\)</span> at node <span class="math inline">\(t\)</span>, and <span class="math inline">\(J\)</span> is the total number of classes. The decision to split at a particular node aims to produce subsets with lower entropy compared to the parent node.</p>
<p><strong>Comparison and Usage in Decision Trees</strong></p>
<p>Both Gini impurity and entropy aim to measure the homogeneity of a dataset; they are just different mathematical methods for doing so. The choice between using Gini impurity or entropy for building a decision tree often depends on the specific dataset and problem context, though in practice, the difference in the trees they produce is often quite small.</p>
<ul>
<li>
<strong>Gini Impurity</strong> is faster to compute, as it doesn’t involve logarithmic functions, which makes it a good default choice for decision tree learning algorithms.</li>
<li>
<strong>Entropy</strong> might produce slightly more balanced trees because it tends to penalize non-uniform class distributions more heavily than Gini impurity.</li>
</ul></section><section id="internal-nodes" class="level4"><h4 class="anchored" data-anchor-id="internal-nodes">2. <strong>Internal Nodes</strong>:</h4>
<p>Internal nodes play a crucial role in the structure and functioning of decision trees, acting as decision points that guide the splitting of the dataset into increasingly homogeneous subsets based on the values of different features. Each internal node represents a “test” or “question” applied to a particular attribute or feature, determining the path down the tree that an observation will follow.</p>
<p><strong>Characteristics of Internal Nodes</strong></p>
<ul>
<li><p><strong>Feature Selection</strong>: Each internal node tests a specific attribute or feature of the data. The choice of which feature to test at each node is determined by a criterion that aims to maximize the homogeneity of the subsets created by the split. For classification tasks, this criterion is often Gini impurity or entropy, whereas for regression tasks, variance reduction is commonly used.</p></li>
<li><p><strong>Decision Point</strong>: An internal node divides the dataset into two or more paths, typically representing different outcomes of the test applied. In binary decision trees, which are the most common, each internal node has exactly two branches, but multiway splits are also possible in other types of decision trees.</p></li>
<li><p><strong>Recursive Splitting</strong>: After a dataset is split at an internal node, the process of feature selection and splitting is applied recursively to each child subset. This process continues until a stopping criterion is met, such as reaching a maximum tree depth, achieving a subset size smaller than a predefined threshold, or when no further improvement in homogeneity can be achieved.</p></li>
</ul>
<p><strong>Process of Creating Internal Nodes</strong></p>
<p>The process of creating internal nodes involves several key steps:</p>
<ol type="1">
<li><p><strong>Feature Selection and Split Criterion</strong>: At each step, the decision tree algorithm evaluates each feature to determine which one to use for splitting the dataset at the current node. This involves calculating the chosen metric (e.g., Gini impurity, entropy, or variance reduction) for every possible split and selecting the feature and split point that result in the highest gain (i.e., the greatest reduction in impurity or variance).</p></li>
<li><p><strong>Dataset Splitting</strong>: Once the best feature and split point are identified, the dataset is divided into two or more subsets according to the outcomes of the test at the internal node. Each subset corresponds to a branch leading to a child node.</p></li>
<li><p><strong>Recursive Application</strong>: The algorithm then recursively applies the same process of feature selection and dataset splitting to each child subset, creating further internal nodes and branches, until stopping criteria are met.</p></li>
</ol>
<p><strong>Example: The Iris Dataset</strong></p>
<p>Consider a decision tree being trained on the Iris dataset. An internal node might test the petal length of an iris flower. Suppose the best split identified at this node is to divide the dataset into flowers with a petal length less than 2.5 cm and those with a petal length greater than or equal to 2.5 cm. This test on petal length is the “question” posed by the internal node, and it effectively separates Iris setosa (which typically has shorter petals) from Iris versicolor and Iris virginica (which have longer petals). Each of the resulting subsets is then passed to child nodes where further tests (internal nodes) are applied based on other features, such as petal width or sepal length, following the same process of maximizing homogeneity within the subsets.</p>
<p>Internal nodes are thus the mechanism by which decision trees make sequential decisions, leading to the classification or regression predictions at the leaf nodes. Their creation and organization within the tree are fundamental to the model’s ability to accurately represent and predict the underlying relationships in the data.</p>
</section><section id="leaf-nodes-leaf-nodes-in-decision-trees-are-the-terminal-points-where-decisions-are-made-or-values-are-predicted-concluding-the-path-from-the-root-through-the-internal-nodes-based-on-the-attributes-of-the-data-being-analyzed.-these-nodes-do-not-split-any-further-and-represent-the-final-output-of-the-decision-making-process-within-the-tree-structure.-in-the-context-of-decision-trees-there-are-two-primary-types-of-tasks-they-can-be-used-for-each-defining-what-a-leaf-node-represents" class="level4"><h4 class="anchored" data-anchor-id="leaf-nodes-leaf-nodes-in-decision-trees-are-the-terminal-points-where-decisions-are-made-or-values-are-predicted-concluding-the-path-from-the-root-through-the-internal-nodes-based-on-the-attributes-of-the-data-being-analyzed.-these-nodes-do-not-split-any-further-and-represent-the-final-output-of-the-decision-making-process-within-the-tree-structure.-in-the-context-of-decision-trees-there-are-two-primary-types-of-tasks-they-can-be-used-for-each-defining-what-a-leaf-node-represents">3. <strong>Leaf Nodes</strong>: Leaf nodes in decision trees are the terminal points where decisions are made or values are predicted, concluding the path from the root through the internal nodes based on the attributes of the data being analyzed. These nodes do not split any further and represent the final output of the decision-making process within the tree structure. In the context of decision trees, there are two primary types of tasks they can be used for, each defining what a leaf node represents:</h4>
<ol type="1">
<li><p><strong>Classification Trees</strong>: In classification tasks, each leaf node is associated with a class label. The path from the root to a leaf node corresponds to a series of decisions based on the attributes of the dataset that leads to a classification decision. For example, in a decision tree designed to classify emails as “spam” or “not spam”, a leaf node would represent one of these two categories. The classification at a leaf is determined by the majority class of the samples that end up in the leaf after applying the decision rules encoded in the tree’s structure. The decision-making process is straightforward; starting from the root, the tree evaluates the attributes of the instance at each internal node, making a decision at each step on which branch to follow, until it reaches a leaf node that provides the final classification.</p></li>
<li><p><strong>Regression Trees</strong>: For regression tasks, each leaf node predicts a continuous value. Instead of leading to a categorical outcome, the path through the tree culminates in a prediction of a numeric quantity. This could be, for instance, the predicted price of a house based on features like its size, age, and location. In regression trees, the value assigned to a leaf node is usually the mean or median of the values of the instances that fall into that leaf, providing a prediction for new instances that reach the leaf.</p></li>
</ol>
<p><strong>The Role and Importance of Leaf Nodes</strong>:</p>
<ul>
<li>
<strong>Final Output</strong>: Leaf nodes represent the decision or prediction outcome of the tree, making them critically important to the tree’s overall purpose. They are the actionable results derived from the series of tests conducted at internal nodes.</li>
<li>
<strong>Interpretability</strong>: The path to a leaf node, consisting of a series of decisions based on clear criteria, contributes to the interpretability of decision trees. One can easily trace back the decisions made by the tree to understand why a particular prediction or classification was made.</li>
<li>
<strong>Simplicity</strong>: Despite their simplicity, leaf nodes encapsulate the complex decision-making process of a decision tree, making complex data relationships understandable through a series of binary decisions.</li>
<li>
<strong>Model Performance</strong>: The creation of leaf nodes is directly influenced by the criteria used to split data at internal nodes (e.g., Gini impurity, entropy, variance reduction). These criteria aim to maximize the homogeneity of the data points within each leaf, which is crucial for the model’s accuracy and ability to generalize.</li>
</ul></section></section><section id="example-using-tidymodels" class="level2" data-number="5.3"><h2 data-number="5.3" class="anchored" data-anchor-id="example-using-tidymodels">
<span class="header-section-number">5.3</span> Example Using <code>tidymodels</code>
</h2>
<p>To illustrate the use of decision trees with <code>tidymodels</code> in R, let’s consider a simple example where we predict the species of the iris flower based on its measurements. This example involves creating a decision tree classification model.</p>
<section id="setting-up-the-environment" class="level4"><h4 class="anchored" data-anchor-id="setting-up-the-environment">Setting Up the Environment</h4>
<p>First, ensure you have <code>tidymodels</code> and <code>rpart</code> packages installed. The <code>rpart</code> package is used for creating decision trees.</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bethatkinson/rpart">rpart</a></span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="preparing-the-data" class="level4"><h4 class="anchored" data-anchor-id="preparing-the-data">Preparing the Data</h4>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># For reproducibility</span></span>
<span></span>
<span><span class="co"># Split the data into training and testing sets</span></span>
<span><span class="va">iris_split</span> <span class="op">=</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">iris</span>, prop <span class="op">=</span> <span class="fl">0.75</span><span class="op">)</span></span>
<span><span class="va">iris_train</span> <span class="op">=</span> <span class="fu">training</span><span class="op">(</span><span class="va">iris_split</span><span class="op">)</span></span>
<span><span class="va">iris_test</span> <span class="op">=</span> <span class="fu">testing</span><span class="op">(</span><span class="va">iris_split</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#setup data for cross validation to tune the model</span></span>
<span><span class="va">dat_folds</span> <span class="op">=</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">iris_train</span>, v <span class="op">=</span> <span class="fl">5</span>, strata <span class="op">=</span> <span class="va">Species</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="creating-the-model-and-recipe" class="level4"><h4 class="anchored" data-anchor-id="creating-the-model-and-recipe">Creating the Model and Recipe</h4>
<p>Note that there are two hyperparameters we need to determine for decision trees. They are:</p>
<ul>
<li>
<code>tree_depth</code> which is the maximum number of node levels the tree can have</li>
<li>
<code>min_n1</code> which is the minimum number of observations in a node that are required for the node to be split further.</li>
</ul>
<p>We will fine tune these hyperparameters using cross validation.</p>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Define the model specification</span></span>
<span><span class="va">dt_model</span> <span class="op">=</span> <span class="fu">decision_tree</span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>, </span>
<span>                          min_n <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"rpart"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"classification"</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">recipe</span> <span class="op">=</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">Species</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">iris_train</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="fine-tune-the-model" class="level4"><h4 class="anchored" data-anchor-id="fine-tune-the-model">Fine Tune the Model</h4>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#setup the possible values of the hyperparameters.</span></span>
<span><span class="co">#by default, tree_depth checks values from 1 to 15</span></span>
<span><span class="co">#min_n defaults to values between, 2 and 40</span></span>
<span><span class="va">tuning_grid</span> <span class="op">=</span> <span class="fu">grid_regular</span><span class="op">(</span></span>
<span>  <span class="fu">tree_depth</span><span class="op">(</span><span class="op">)</span>,</span>
<span>  <span class="fu">min_n</span><span class="op">(</span><span class="op">)</span>,</span>
<span>  levels <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co">#fine tune the model</span></span>
<span><span class="va">tune_results</span> <span class="op">=</span> <span class="fu">tune_grid</span><span class="op">(</span></span>
<span>  object <span class="op">=</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">add_recipe</span><span class="op">(</span><span class="va">recipe</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">add_model</span><span class="op">(</span><span class="va">dt_model</span><span class="op">)</span>,</span>
<span>  resamples <span class="op">=</span> <span class="va">dat_folds</span>,</span>
<span>  grid <span class="op">=</span> <span class="va">tuning_grid</span>,</span>
<span>  metrics <span class="op">=</span> <span class="fu">metric_set</span><span class="op">(</span><span class="va">accuracy</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">best_params</span> <span class="op">=</span> <span class="fu">select_best</span><span class="op">(</span><span class="va">tune_results</span>, metric <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span></span>
<span><span class="va">best_params</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
  tree_depth min_n .config               
       &lt;int&gt; &lt;int&gt; &lt;chr&gt;                 
1          4     2 Preprocessor1_Model003</code></pre>
</div>
</div>
</section><section id="fit-the-final-model" class="level4"><h4 class="anchored" data-anchor-id="fit-the-final-model">Fit the final model</h4>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fitted_model</span> <span class="op">=</span> <span class="fu">finalize_workflow</span><span class="op">(</span></span>
<span>      <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>        <span class="fu">add_recipe</span><span class="op">(</span><span class="va">recipe</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>        <span class="fu">add_model</span><span class="op">(</span><span class="va">dt_model</span><span class="op">)</span>,</span>
<span>      <span class="va">best_params</span></span>
<span>    <span class="op">)</span> <span class="op">|&gt;</span></span>
<span>      <span class="fu">fit</span><span class="op">(</span>data <span class="op">=</span> <span class="va">iris_train</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s first examine how well we fit the training data.</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">pred_train</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fitted_model</span>, new_data <span class="op">=</span> <span class="va">iris_train</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">bind_cols</span><span class="op">(</span><span class="va">iris_train</span><span class="op">)</span></span>
<span><span class="va">train_metrics</span> <span class="op">=</span> <span class="fu">metrics</span><span class="op">(</span><span class="va">pred_train</span>, truth <span class="op">=</span> <span class="va">Species</span>, estimate <span class="op">=</span> <span class="va">.pred_class</span><span class="op">)</span></span>
<span><span class="va">train_conf_mat</span> <span class="op">=</span> <span class="fu">conf_mat</span><span class="op">(</span><span class="va">pred_train</span>, truth <span class="op">=</span> <span class="va">Species</span>, estimate <span class="op">=</span> <span class="va">.pred_class</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">train_metrics</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  .metric  .estimator .estimate
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
1 accuracy multiclass     0.991
2 kap      multiclass     0.987</code></pre>
</div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">train_conf_mat</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Truth
Prediction   setosa versicolor virginica
  setosa         38          0         0
  versicolor      0         32         0
  virginica       0          1        41</code></pre>
</div>
</div>
<p>We can visualize the decision tree using the <code>rpart.plot</code> library.</p>
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.milbo.org/rpart-plot/index.html">rpart.plot</a></span><span class="op">)</span></span>
<span><span class="va">tree_fit</span> <span class="op">=</span> <span class="va">fitted_model</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">extract_fit_parsnip</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/rpart.plot/man/rpart.plot.html">rpart.plot</a></span><span class="op">(</span><span class="va">tree_fit</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="05_Decision_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="576"></p>
</div>
</div>
</section><section id="predicting-and-evaluating" class="level4"><h4 class="anchored" data-anchor-id="predicting-and-evaluating">Predicting and Evaluating</h4>
<p>Let’s now predict the testing data.</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Make predictions</span></span>
<span><span class="va">predictions</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fitted_model</span>, <span class="va">iris_test</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">bind_cols</span><span class="op">(</span><span class="va">iris_test</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Evaluate the model</span></span>
<span><span class="va">test_metrics</span> <span class="op">=</span> <span class="fu">metrics</span><span class="op">(</span><span class="va">predictions</span>, truth <span class="op">=</span> <span class="va">Species</span>, estimate <span class="op">=</span> <span class="va">.pred_class</span><span class="op">)</span></span>
<span><span class="va">test_conf_mat</span> <span class="op">=</span> <span class="fu">conf_mat</span><span class="op">(</span><span class="va">predictions</span>, truth <span class="op">=</span> <span class="va">Species</span>, estimate <span class="op">=</span> <span class="va">.pred_class</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">test_metrics</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  .metric  .estimator .estimate
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
1 accuracy multiclass     0.947
2 kap      multiclass     0.920</code></pre>
</div>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">test_conf_mat</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>            Truth
Prediction   setosa versicolor virginica
  setosa         12          0         0
  versicolor      0         15         0
  virginica       0          2         9</code></pre>
</div>
</div>
<p>Note that the accuracy is slightly below the training data accuracy.</p>
</section></section><section id="decision-trees-for-regression" class="level2" data-number="5.4"><h2 data-number="5.4" class="anchored" data-anchor-id="decision-trees-for-regression">
<span class="header-section-number">5.4</span> 4. Decision Trees for Regression</h2>
<p>Regression trees are used when the target variable is continuous. Instead of predicting a class for each instance, regression trees predict a real number. For example, a regression tree might predict the price of a house based on features such as the number of bedrooms, the house’s age, and its location.</p>
<p><strong>Example: Diamonds dataset</strong></p>
<div class="cell">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span> <span class="co"># For the diamonds dataset</span></span>
<span></span>
<span><span class="co"># Load the diamonds dataset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">diamonds</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Sample for a manageable size</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">diamonds_sample</span> <span class="op">=</span> <span class="va">diamonds</span> <span class="op">|&gt;</span> <span class="fu">sample_n</span><span class="op">(</span><span class="fl">2000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Initial data split</span></span>
<span><span class="va">split</span> <span class="op">=</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">diamonds_sample</span>, prop <span class="op">=</span> <span class="fl">0.75</span><span class="op">)</span></span>
<span><span class="va">train_data</span> <span class="op">=</span> <span class="fu">training</span><span class="op">(</span><span class="va">split</span><span class="op">)</span></span>
<span><span class="va">test_data</span> <span class="op">=</span> <span class="fu">testing</span><span class="op">(</span><span class="va">split</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#setup data for cross validation to tune the model</span></span>
<span><span class="va">dat_folds</span> <span class="op">=</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">train_data</span>, v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a recipe</span></span>
<span><span class="va">recipe</span> <span class="op">=</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">price</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#setup model</span></span>
<span><span class="va">dt_model</span> <span class="op">=</span> <span class="fu">decision_tree</span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>, </span>
<span>                          min_n <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"rpart"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#setup tuning grid</span></span>
<span><span class="va">tuning_grid</span> <span class="op">=</span> <span class="fu">grid_regular</span><span class="op">(</span></span>
<span>  <span class="fu">tree_depth</span><span class="op">(</span><span class="op">)</span>,</span>
<span>  <span class="fu">min_n</span><span class="op">(</span><span class="op">)</span>,</span>
<span>  levels <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co">#fine tune the model</span></span>
<span><span class="va">tune_results</span> <span class="op">=</span> <span class="fu">tune_grid</span><span class="op">(</span></span>
<span>  object <span class="op">=</span> <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">add_recipe</span><span class="op">(</span><span class="va">recipe</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">add_model</span><span class="op">(</span><span class="va">dt_model</span><span class="op">)</span>,</span>
<span>  resamples <span class="op">=</span> <span class="va">dat_folds</span>,</span>
<span>  grid <span class="op">=</span> <span class="va">tuning_grid</span>,</span>
<span>  metrics <span class="op">=</span> <span class="fu">metric_set</span><span class="op">(</span><span class="va">rmse</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co">#get the best hyperparameters</span></span>
<span><span class="va">best_params</span> <span class="op">=</span> <span class="fu">select_best</span><span class="op">(</span><span class="va">tune_results</span>, metric <span class="op">=</span> <span class="st">"rmse"</span><span class="op">)</span></span>
<span><span class="va">best_params</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
  tree_depth min_n .config               
       &lt;int&gt; &lt;int&gt; &lt;chr&gt;                 
1          5     2 Preprocessor1_Model004</code></pre>
</div>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#fit the final model</span></span>
<span><span class="va">fitted_model</span> <span class="op">=</span> <span class="fu">finalize_workflow</span><span class="op">(</span></span>
<span>  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">add_recipe</span><span class="op">(</span><span class="va">recipe</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu">add_model</span><span class="op">(</span><span class="va">dt_model</span><span class="op">)</span>,</span>
<span>  <span class="va">best_params</span></span>
<span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">fit</span><span class="op">(</span>data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co">#see how well the model fit the training data</span></span>
<span><span class="va">pred_train</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fitted_model</span>, new_data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">bind_cols</span><span class="op">(</span><span class="va">train_data</span><span class="op">)</span></span>
<span><span class="va">train_metrics</span> <span class="op">=</span> <span class="fu">metrics</span><span class="op">(</span><span class="va">pred_train</span>, truth <span class="op">=</span> <span class="va">price</span>, estimate <span class="op">=</span> <span class="va">.pred</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">train_metrics</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
  .metric .estimator .estimate
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
1 rmse    standard    1222.   
2 rsq     standard       0.905
3 mae     standard     802.   </code></pre>
</div>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#visualize the tree</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.milbo.org/rpart-plot/index.html">rpart.plot</a></span><span class="op">)</span></span>
<span><span class="va">tree_fit</span> <span class="op">=</span> <span class="va">fitted_model</span> <span class="op">|&gt;</span></span>
<span><span class="fu">extract_fit_parsnip</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/rpart.plot/man/rpart.plot.html">rpart.plot</a></span><span class="op">(</span><span class="va">tree_fit</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="05_Decision_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="576"></p>
</div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Make predictions and gauge performance on test data</span></span>
<span><span class="va">predictions</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fitted_model</span>, <span class="va">test_data</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">bind_cols</span><span class="op">(</span><span class="va">test_data</span><span class="op">)</span></span>
<span><span class="va">test_metrics</span> <span class="op">=</span> <span class="fu">metrics</span><span class="op">(</span><span class="va">predictions</span>, truth <span class="op">=</span> <span class="va">price</span>, estimate <span class="op">=</span> <span class="va">.pred</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">test_metrics</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 3
  .metric .estimator .estimate
  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
1 rmse    standard    1412.   
2 rsq     standard       0.876
3 mae     standard     916.   </code></pre>
</div>
</div>
</section><section id="advantages-and-disadvantages" class="level2" data-number="5.5"><h2 data-number="5.5" class="anchored" data-anchor-id="advantages-and-disadvantages">
<span class="header-section-number">5.5</span> Advantages and Disadvantages</h2>
<p>Decision trees offer several advantages. First, they are simple and interpretable—trees can be visualized and easily understood, even by non-experts, making them especially useful for decision support. They are also flexible, as they can handle both numerical and categorical data. Additionally, their non-parametric nature means they do not assume any specific distribution of the data, making them well-suited for capturing non-linear relationships.</p>
<p>However, decision trees also have notable disadvantages. They are prone to overfitting; without proper pruning, they can become overly complex and fail to generalize to new data. They can also be unstable, as small changes in the dataset can result in significantly different trees. Finally, because the algorithm used to build decision trees is greedy—making the best local choice at each step—it may miss the globally optimal solution.</p>


</section></main><!-- /main --><script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  var t = document.getElementsByClassName("webex-total_correct");
  for (var i = 0; i < t.length; i++) {
    p = t[i].parentElement;
    var correct = p.getElementsByClassName("webex-correct").length;
    var solvemes = p.getElementsByClassName("webex-solveme").length;
    var radiogroups = p.getElementsByClassName("webex-radiogroup").length;
    var selects = p.getElementsByClassName("webex-select").length;

    t[i].innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");

  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* check answers */
check_func = function() {
  console.log("webex: check answers");

  var cl = this.parentElement.classList;
  if (cl.contains('unchecked')) {
    cl.remove("unchecked");
    this.innerHTML = "Hide Answers";
  } else {
    cl.add("unchecked");
    this.innerHTML = "Show Answers";
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");

  var cl = this.classList

  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;

  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }

  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

window.onload = function() {
  console.log("webex onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  var check_sections = document.getElementsByClassName("webex-check");
  console.log("check:", check_sections.length);
  for (var i = 0; i < check_sections.length; i++) {
    check_sections[i].classList.add("unchecked");

    let btn = document.createElement("button");
    btn.innerHTML = "Show Answers";
    btn.classList.add("webex-check-button");
    btn.onclick = check_func;
    check_sections[i].appendChild(btn);

    let spn = document.createElement("span");
    spn.classList.add("webex-total_correct");
    check_sections[i].appendChild(spn);
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;

    solveme[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }

  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
    selects[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  update_total_correct();
}

</script><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./04_SVM.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./06_Ensemble.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Ensemble Learning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">STA 5320</div>
  </div>
</footer>


</body></html>